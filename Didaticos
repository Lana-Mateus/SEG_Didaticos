# Carregamento de Pacotes.......................................................

pacman::p_load (
dplyr,
stringr,
readtext,
tidyr,
tidytext,
tm,
stopwords,
quanteda,
quanteda.textstats,
flextable)

# Criação do Banco de Dados.....................................................

bd_livros = readtext("C:\\Users\\lanam\\OneDrive\\Área de Trabalho\\Didatico_cortado\\*",
                     docvarsfrom = "filenames")
                     # modificar o diretório acima para o seu

# Limpeza de Dados..............................................................

bd_livros = bd_livros %>% select(-docvar1) #remove variável não necessaria para análise
bd_livros$text = gsub("[.,;]", "", bd_livros$text) #remove ponto, vírgula e ponto e vírgula do texto
bd_livros$text = gsub("\\s+", " ", bd_livros$text) #remove espaços excessivos (uso do pacote estava dando erro)
bd_livros$text = tolower(bd_livros$text) #coloca todas as letras em minúsculo

# Removendo acentuação..........................................................

remove.acentos = function(s) {
  com = "áéíóúâêôûãõàèìòùäëïöüç"
  sem = "aeiouaeouaoaeiouaeiouc"
  novo = chartr(com, sem, s)
  
  return(novo)
} # criação de função
bd_livros$text = remove.acentos(bd_livros$text) #aplicação de função

# Análise de Palavras...........................................................

bd_livros_corpus = Corpus(VectorSource(bd_livros$text))
bd_livros_texto = as.character(bd_livros_corpus)

palavras = tokens(bd_livros_texto,
                  remove_numbers = TRUE,
                  remove_symbols = TRUE,
                  remove_punct = TRUE,
                  remove_separators = TRUE) %>%
  tokens_remove(pattern = c(stopwords(language = "pt"),
                            "nao", "sao", "d", "sobre", "ser", "tambem", "i", "p", "es", "c", "b", "n", "ate", "s", "ja", "re", "so", "in", "m", "t", "ha", "muitos", "r","paulo","ed","ac","co","assim","durante","unidade","doc","quais","onde","alguns","cada","ainda","capitulo","forma","partir","rio","janeiro","ca","ta","tra","ii","apos","havia","alem","media","sob","segundo","outras","outros","la","porem","disso","muitas","entao","voce","po","to","desse","modo","con","estao", 
                            # as letras acima são letras para serem retiradas do banco de dados das palavras repetidas e podem ser adapatadas conforme necessidade
                            padding= FALSE))

palavras_dfm = dfm(palavras)
palavras_mais_repetidas = textstat_frequency(palavras_dfm, n = 100) # adaptar o "n=100" para a quantidade de palavras que você quiser
palavras_mais_repetidas = palavras_mais_repetidas %>% select(-rank)
palavras_mais_repetidas = palavras_mais_repetidas %>% select(-docfreq)
palavras_mais_repetidas = palavras_mais_repetidas %>% select(-group)
